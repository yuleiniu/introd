exp:
  dir: logs/vqacp2/smrl_rubi
  resume: # last, best_[...], or empty (from scratch)
dataset:
  import: cfvqa.datasets.factory
  name: vqacp2 # or vqa2vg
  dir: data/vqa/vqacp2
  train_split: train
  eval_split: val # or test
  proc_split: train # or trainval (preprocessing split, must be equal to train_split)
  nb_threads: 4
  batch_size: 256
  nans: 3000
  minwcount: 0
  nlp: mcb
  samplingans: True
  dir_rcnn: data/vqa/coco/extract_rcnn/2018-04-27_bottom-up-attention_fixed_36
model:
  name: default
  network:
    import: cfvqa.models.networks.factory
    base: smrl
    name: rubi
    rubi_params:
      mlp_q:
        input_dim: 4800
        dimensions: [1024,1024,3000]
    txt_enc:
      name: skipthoughts
      type: BayesianUniSkip
      dropout: 0.25
      fixed_emb: False
      dir_st: data/skip-thoughts
    self_q_att: True
    residual: False
    q_single: False
    fusion:
      type: block
      input_dims: [4800, 2048]
      output_dim: 2048
      mm_dim: 1000
      chunks: 20
      rank: 15
      dropout_input: 0.
      dropout_pre_lin: 0.
    agg:
      type: max
    classif:
      mlp:
        input_dim: 2048
        dimensions: [1024,1024,3000]
  criterion:
    import: cfvqa.models.criterions.factory
    name: rubi_criterion
    question_loss_weight: 1.0
  metric:
    import: cfvqa.models.metrics.factory
    name: vqa_rubi_metrics
optimizer:
  import: cfvqa.optimizers.factory
  name: Adam
  lr: 0.0003
  gradual_warmup_steps: [0.5, 2.0, 7.0] #torch.linspace
  gradual_warmup_steps_mm: [0.5, 2.0, 7.0] #torch.linspace
  lr_decay_epochs: [14, 24, 2] #range
  lr_decay_rate: .25
engine:
  name: logger
  debug: False
  print_freq: 10
  nb_epochs: 22
  saving_criteria:
  - eval_epoch.accuracy_top1:max
  - eval_epoch.accuracy_all_top1:max
misc:
  logs_name:
  cuda: True
  seed: 1337
